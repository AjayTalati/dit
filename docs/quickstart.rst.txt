Quickstart
----------

The basic usage of ``dit`` corresponds to creating distributions, modifying
them if need be, and then computing properties of those distributions.
First, we import::

    >>> import dit

Now, we create a distribution representing a biased coin and print it.::

    >>> d = dit.Distribution(['H', 'T'], [.4, .6])
    >>> print d
    Class:          Distribution
    Alphabet:       ('H', 'T') for all rvs
    Base:           linear
    Outcome Class:  str
    Outcome Length: 1
    RV Names:       None

    x   p(x)
    H   0.4
    T   0.6

Calculate the probability of :math:`H` and also of the combination:
:math:`H~ \mathbf{or}~T`. ::

    >>> d['H']
    0.4
    >>> d.event_probability(['H','T'])
    1.0

Create a distribution representing the :math:`\mathbf{xor}` logic function.  Here, we have two inputs, :math:`X` and :math:`Y`, and then an output
:math:`Z = \mathbf{xor}(X,Y)`.::

    >>> import dit.example_dists
    >>> d = dit.example_dists.Xor()
    >>> d.set_rv_names(['X', 'Y', 'Z'])
    >>> print d
    Class:          Distribution
    Alphabet:       ('0', '1') for all rvs
    Base:           linear
    Outcome Class:  str
    Outcome Length: 3
    RV Names:       ('X', 'Y', 'Z')

    x     p(x)
    000   0.25
    011   0.25
    101   0.25
    110   0.25

Calculate the Shannon entropy and extropy of the joint distribution. ::

    >>> dit.algorithms.entropy(d)
    0.97095059445466858
    >>> dit.algorithms.extropy(d)
    1.2451124978365313

Calculate the Shannon mutual informations :math:`I[X:Z]`, :math:`I[Y:Z]`,
:math:`I[X,Y:Z]`. ::

    >>> dit.algorithms.mutual_information(d, ['X'], ['Z'])
    0.0
    >>> dit.algorithms.mutual_information(d, ['Y'], ['Z'])
    0.0
    >>> dit.algorithms.mutual_information(d, ['X', 'Y'], ['Z'])
    1.0

Calculate the marginal distribution :math:`P(X,Z)`. Then print its probabilities as fractions, showing the mask. ::

    >>> d2 = d.marginal(['X', 'Z'])
    >>> print d2.to_string(show_mask=True, exact=True)
    Class:          Distribution
    Alphabet:       ('0', '1') for all rvs
    Base:           linear
    Outcome Class:  str
    Outcome Length: 2 (mask: 3)
    RV Names:       ('X', 'Z')

    x     p(x)
    0*0   1/4
    0*1   1/4
    1*0   1/4
    1*1   1/4

Convert the distribution probabilities to log (base 3.5) probabilities, and access its probability mass function. ::

    >>> d2.set_base(3.5)
    >>> d2.pmf
    array([-1.10658951, -1.10658951, -1.10658951, -1.10658951])

Draw 5 random samples from this distribution. ::

    >>> d2.rand(5)
    ['10', '11', '00', '01', '10']


